{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7a38f860-9f76-4703-b63f-0722356c5a0f",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98a730c0-2e91-4383-b259-80937925e5c9",
   "metadata": {},
   "source": [
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "chrome_driver_path = \"C:\\\\Program Files\\\\Google\\\\Chrome\\\\Application\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chrome_driver_path)\n",
    "\n",
    "browser = webdriver.Chrome(service=service)\n",
    "url =\n",
    "\n",
    "browser.set_window_size(1024, 960)\n",
    "browser.get(url)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a371b4a1-699c-4494-89e0-5745116f6fd6",
   "metadata": {},
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "# å„²å­˜è³‡æ–™å¤¾è·¯å¾‘\n",
    "save_path = r\"C:\\Users\\Mao-k\\ç¶²é çˆ¬èŸ²\\Final_Project\\Web_crawel_Data\\LetterBox_movie\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# è¨­å®š Selenium\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "try:\n",
    "    # Step 1ï¼šæœå°‹é›»å½±\n",
    "    search_query = \"æ‚²æƒ…åŸå¸‚\"\n",
    "    search_url = f\"https://letterboxd.com/search/{search_query}/\"\n",
    "    driver.get(search_url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Step 2ï¼šé»æ“Šç¬¬ä¸€ç­†çµæœ\n",
    "    movie_link = driver.find_element(By.XPATH, '//ul[@class=\"results\"]/li//a[contains(@href, \"/film/\")]')\n",
    "    movie_link.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Step 3ï¼šè§£æé é¢\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Step 4ï¼šæ“·å–åŸºæœ¬è³‡æ–™\n",
    "    title = soup.find(\"h1\", class_=\"headline-1\").text.strip() if soup.find(\"h1\", class_=\"headline-1\") else \"N/A\"\n",
    "\n",
    "    year_tag = soup.select_one(\"div.metablock div.releaseyear a\")\n",
    "    year = year_tag.text.strip() if year_tag else \"N/A\"\n",
    "\n",
    "    description_tag = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "    description = description_tag[\"content\"] if description_tag else \"N/A\"\n",
    "\n",
    "    poster_a_tag = soup.find(\"a\", attrs={\"data-js-trigger\": \"postermodal\"})\n",
    "    poster_url = poster_a_tag[\"href\"] if poster_a_tag else \"N/A\"\n",
    "\n",
    "    # Step 5ï¼šå¹³å‡åˆ†æ•¸èˆ‡ç¸½è©•åƒ¹æ•¸\n",
    "    average_score = \"N/A\"\n",
    "    total_ratings = \"N/A\"\n",
    "    rating_block = soup.select_one('section.ratings-histogram-chart')\n",
    "    if rating_block:\n",
    "        avg_tag = rating_block.select_one('span.average-rating a')\n",
    "        if avg_tag:\n",
    "            title_text = avg_tag.get('data-original-title', '')\n",
    "            match = re.search(r'([\\d.]+).*?based on ([\\d,]+)', title_text)\n",
    "            if match:\n",
    "                average_score = match.group(1)\n",
    "                total_ratings = match.group(2).replace(',', '')\n",
    "\n",
    "    # Step 6ï¼šæ“·å–å„æ˜Ÿç­‰çš„è©•åƒ¹æ•¸é‡ï¼ˆâ˜… ä¿®æ­£è™•ï¼‰\n",
    "    star_ratings = {\n",
    "        '0.5': 0, '1': 0, '1.5': 0, '2': 0, '2.5': 0,\n",
    "        '3': 0, '3.5': 0, '4': 0, '4.5': 0, '5': 0\n",
    "    }\n",
    "\n",
    "    rating_map = {\n",
    "        'half-â˜…': '0.5', 'â˜…': '1', 'â˜…Â½': '1.5', 'â˜…â˜…': '2', 'â˜…â˜…Â½': '2.5',\n",
    "        'â˜…â˜…â˜…': '3', 'â˜…â˜…â˜…Â½': '3.5', 'â˜…â˜…â˜…â˜…': '4', 'â˜…â˜…â˜…â˜…Â½': '4.5', 'â˜…â˜…â˜…â˜…â˜…': '5'\n",
    "    }\n",
    "\n",
    "    for li in soup.select('li.rating-histogram-bar'):\n",
    "        a_tag = li.find('a')\n",
    "        if a_tag:\n",
    "            tooltip = a_tag.get(\"data-original-title\", \"\")\n",
    "            match = re.search(r'([\\d,]+)\\s+([\\S]+) ratings', tooltip)\n",
    "            if match:\n",
    "                count = int(match.group(1).replace(\",\", \"\"))\n",
    "                stars_text = match.group(2)\n",
    "                rating_value = rating_map.get(stars_text)\n",
    "                if rating_value:\n",
    "                    star_ratings[rating_value] = count\n",
    "\n",
    "    # Step 7ï¼šå»ºç«‹ DataFrame ä¸¦åŒ¯å‡º CSV\n",
    "    movie_data = [{\n",
    "        \"é›»å½±æ¨™é¡Œ\": title,\n",
    "        \"ä¸Šæ˜ å¹´ä»½\": year,\n",
    "        \"é›»å½±æè¿°\": description,\n",
    "        \"æµ·å ±åœ–ç‰‡\": poster_url,\n",
    "        \"å¹³å‡è©•åˆ†\": average_score,\n",
    "        \"è©•åˆ†ç¸½æ•¸\": total_ratings,\n",
    "        \"0.5æ˜Ÿ\": star_ratings['0.5'],\n",
    "        \"1æ˜Ÿ\": star_ratings['1'],\n",
    "        \"1.5æ˜Ÿ\": star_ratings['1.5'],\n",
    "        \"2æ˜Ÿ\": star_ratings['2'],\n",
    "        \"2.5æ˜Ÿ\": star_ratings['2.5'],\n",
    "        \"3æ˜Ÿ\": star_ratings['3'],\n",
    "        \"3.5æ˜Ÿ\": star_ratings['3.5'],\n",
    "        \"4æ˜Ÿ\": star_ratings['4'],\n",
    "        \"4.5æ˜Ÿ\": star_ratings['4.5'],\n",
    "        \"5æ˜Ÿ\": star_ratings['5']\n",
    "    }]\n",
    "\n",
    "    df = pd.DataFrame(movie_data)\n",
    "    csv_path = os.path.join(save_path, f\"{search_query}_movie_info.csv\")\n",
    "    df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"âœ… æˆåŠŸå„²å­˜ï¼š{csv_path}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c60e39ec-3dd0-420d-9428-c5f9e40d1960",
   "metadata": {},
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def convert_rating_to_number(rating_str):\n",
    "    if not rating_str:\n",
    "        return \"\"\n",
    "    stars = rating_str.count(\"â˜…\")\n",
    "    half = \"Â½\" in rating_str\n",
    "    return stars + 0.5 if half else stars\n",
    "\n",
    "def get_letterboxd_reviews(movie_url, search_term):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--window-size=1200,900\")\n",
    "    # chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    reviews_url = movie_url.rstrip(\"/\") + \"/reviews/by/activity/\"\n",
    "\n",
    "    try:\n",
    "        print(f\"ğŸ“„ å‰å¾€è©•è«–é é¢ï¼š{reviews_url}\")\n",
    "        driver.get(reviews_url)\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "\n",
    "        print(\"âŒ› ç­‰å¾…è©•è«–æ¸…å–®è¼‰å…¥...\")\n",
    "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"viewing-list\")))\n",
    "\n",
    "        review_list = driver.find_elements(By.CSS_SELECTOR, \".viewing-list .listitem article\")\n",
    "        print(f\"ğŸ“ æ‰¾åˆ° {len(review_list)} ç­†è©•è«–\")\n",
    "\n",
    "        output_folder = r\"C:\\Users\\Mao-k\\ç¶²é çˆ¬èŸ²\\Final_Project\\Web_crawel_Data\\LetterBox_movie\"\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        filename = f\"{search_term}_reviews.csv\"\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        with open(output_path, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Reviewer\", \"Rating\", \"Date\", \"Content\", \"Likes\"])\n",
    "\n",
    "            for review in review_list:\n",
    "                try:\n",
    "                    reviewer = review.find_element(By.CSS_SELECTOR, \".displayname\").text\n",
    "                except:\n",
    "                    reviewer = \"ç„¡åç¨±\"\n",
    "\n",
    "                try:\n",
    "                    rating_text = review.find_element(By.CSS_SELECTOR, \"span.rating\").text.strip()\n",
    "                    rating = convert_rating_to_number(rating_text)\n",
    "                except:\n",
    "                    rating = \"\"\n",
    "\n",
    "                try:\n",
    "                    date = review.find_element(By.CSS_SELECTOR, \"time.timestamp\").get_attribute(\"datetime\")\n",
    "                except:\n",
    "                    date = \"\"\n",
    "\n",
    "                try:\n",
    "                    content = review.find_element(By.CSS_SELECTOR, \"div.js-review-body\").text.strip()\n",
    "                except:\n",
    "                    content = \"\"\n",
    "\n",
    "                try:\n",
    "                    likes_text = review.find_element(By.CSS_SELECTOR, \"span._count_8kxo2_22\").text\n",
    "                    likes = int(re.search(r\"\\d+\", likes_text.replace(\",\", \"\")).group())\n",
    "                except:\n",
    "                    likes = 0\n",
    "\n",
    "                print(f\"{reviewer} | {rating} | {date} | ğŸ‘ {likes}\")\n",
    "                writer.writerow([reviewer, rating, date, content, likes])\n",
    "\n",
    "        print(f\"âœ… è³‡æ–™å·²å„²å­˜è‡³ï¼š{output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{repr(e)}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "# âœ… ä½¿ç”¨ç¯„ä¾‹\n",
    "get_letterboxd_reviews(\n",
    "    movie_url=\"https://letterboxd.com/film/a-city-of-sadness/\",\n",
    "    search_term=\"a city of sadness\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "338c3233-7f0e-4555-a9ad-70e011881670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"C:/Users/Mao-k/ç¶²é çˆ¬èŸ²/Final_Project_Web_Crawler_2025_Spring/site\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d9821ef-0604-411b-bd98-99d81145a378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸå„²å­˜ï¼šC:\\Users\\Mao-k\\ç¶²é çˆ¬èŸ²\\Final_Project_Web_Crawler_2025_Spring\\Web_crawel_Data\\LetterBox_movie\\ç©å‘½é—œé ­4_movie_info.csv\n",
      "ğŸ“„ å‰å¾€è©•è«–é é¢ï¼šhttps://letterboxd.com/film/fast-furious/reviews/by/activity/\n",
      "âŒ› ç­‰å¾…è©•è«–æ¸…å–®è¼‰å…¥...\n",
      "ğŸ“ æ‰¾åˆ° 12 ç­†è©•è«–\n",
      "Willow Maclay | 3 | 2015-04-05 | ğŸ‘ 2125\n",
      "Josh Larsen | 3.5 | 2015-03-28 | ğŸ‘ 1933\n",
      "Josh Lewis | 2 | 2015-03-25 | ğŸ‘ 1679\n",
      "Andy Young | 3.5 | 2021-06-19 | ğŸ‘ 1186\n",
      "Lucy | 2 | 2021-06-22 | ğŸ‘ 970\n",
      "Matt Singer | 3.5 | 2021-06-24 | ğŸ‘ 838\n",
      "Bryan Espitia | 3.5 | 2021-05-21 | ğŸ‘ 651\n",
      "Bryan Espitia | 3.5 | 2023-05-06 | ğŸ‘ 642\n",
      "demi adejuyigbe |  | 2021-06-19 | ğŸ‘ 499\n",
      "Wood | 3 | 2015-04-08 | ğŸ‘ 424\n",
      "Framesofnick | 2 | 2020-07-15 | ğŸ‘ 349\n",
      "Leah ğŸ¥€ | 3 | 2022-03-13 | ğŸ‘ 330\n",
      "âœ… è©•è«–è³‡æ–™å·²å„²å­˜è‡³ï¼šC:\\Users\\Mao-k\\ç¶²é çˆ¬èŸ²\\Final_Project_Web_Crawler_2025_Spring\\Web_crawel_Data\\LetterBox_movie\\ç©å‘½é—œé ­4_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# å„²å­˜è³‡æ–™å¤¾è·¯å¾‘\n",
    "base_path = r\"C:\\Users\\Mao-k\\ç¶²é çˆ¬èŸ²\\Final_Project_Web_Crawler_2025_Spring\"\n",
    "save_path = r\"C:\\Users\\Mao-k\\ç¶²é çˆ¬èŸ²\\Final_Project_Web_Crawler_2025_Spring\\Web_crawel_Data\\LetterBox_movie\"\n",
    "data_folder = r\"C:\\Users\\Mao-k\\ç¶²é çˆ¬èŸ²\\Final_Project_Web_Crawler_2025_Spring\\data\"\n",
    "site = os.path.join(base_path, \"Crawler_code\", \"site\")\n",
    "os.makedirs(site, exist_ok=True)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# è¨­å®š Selenium\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--window-size=1200,900\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "search_query = \"ç©å‘½é—œé ­4\"\n",
    "safe_query = search_query.strip().replace(\" \", \"_\")\n",
    "\n",
    "try:\n",
    "    # Step 1ï¼šæœå°‹é›»å½±\n",
    "    search_url = f\"https://letterboxd.com/search/{search_query}/\"\n",
    "    driver.get(search_url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Step 2ï¼šé»æ“Šç¬¬ä¸€ç­†çµæœ\n",
    "    movie_link = driver.find_element(By.XPATH, '//ul[@class=\"results\"]/li//a[contains(@href, \"/film/\")]')\n",
    "    movie_link.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Step 3ï¼šè§£æé é¢\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Step 4ï¼šæ“·å–åŸºæœ¬è³‡æ–™\n",
    "    title = soup.find(\"h1\", class_=\"headline-1\").text.strip() if soup.find(\"h1\", class_=\"headline-1\") else \"N/A\"\n",
    "\n",
    "    year_tag = soup.select_one(\"div.metablock div.releaseyear a\")\n",
    "    year = year_tag.text.strip() if year_tag else \"N/A\"\n",
    "\n",
    "    description_tag = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "    description = description_tag[\"content\"] if description_tag else \"N/A\"\n",
    "\n",
    "    poster_a_tag = soup.find(\"a\", attrs={\"data-js-trigger\": \"postermodal\"})\n",
    "    poster_url = poster_a_tag[\"href\"] if poster_a_tag else \"N/A\"\n",
    "\n",
    "    # Step 5ï¼šå¹³å‡åˆ†æ•¸èˆ‡ç¸½è©•åƒ¹æ•¸\n",
    "    average_score = \"N/A\"\n",
    "    total_ratings = \"N/A\"\n",
    "    rating_block = soup.select_one('section.ratings-histogram-chart')\n",
    "    if rating_block:\n",
    "        avg_tag = rating_block.select_one('span.average-rating a')\n",
    "        if avg_tag:\n",
    "            title_text = avg_tag.get('data-original-title', '')\n",
    "            match = re.search(r'([\\d.]+).*?based on ([\\d,]+)', title_text)\n",
    "            if match:\n",
    "                average_score = match.group(1)\n",
    "                total_ratings = match.group(2).replace(',', '')\n",
    "\n",
    "    # Step 6ï¼šæ“·å–å„æ˜Ÿç­‰çš„è©•åƒ¹æ•¸é‡\n",
    "    star_ratings = {\n",
    "        '0.5': 0, '1': 0, '1.5': 0, '2': 0, '2.5': 0,\n",
    "        '3': 0, '3.5': 0, '4': 0, '4.5': 0, '5': 0\n",
    "    }\n",
    "\n",
    "    rating_map = {\n",
    "        'half-â˜…': '0.5', 'â˜…': '1', 'â˜…Â½': '1.5', 'â˜…â˜…': '2', 'â˜…â˜…Â½': '2.5',\n",
    "        'â˜…â˜…â˜…': '3', 'â˜…â˜…â˜…Â½': '3.5', 'â˜…â˜…â˜…â˜…': '4', 'â˜…â˜…â˜…â˜…Â½': '4.5', 'â˜…â˜…â˜…â˜…â˜…': '5'\n",
    "    }\n",
    "\n",
    "    for li in soup.select('li.rating-histogram-bar'):\n",
    "        a_tag = li.find('a')\n",
    "        if a_tag:\n",
    "            tooltip = a_tag.get(\"data-original-title\", \"\")\n",
    "            match = re.search(r'([\\d,]+)\\s+([\\S]+) ratings', tooltip)\n",
    "            if match:\n",
    "                count = int(match.group(1).replace(\",\", \"\"))\n",
    "                stars_text = match.group(2)\n",
    "                rating_value = rating_map.get(stars_text)\n",
    "                if rating_value:\n",
    "                    star_ratings[rating_value] = count\n",
    "\n",
    "    # Step 7ï¼šå»ºç«‹ DataFrame ä¸¦åŒ¯å‡º CSV\n",
    "    movie_data = [{\n",
    "        \"é›»å½±æ¨™é¡Œ\": title,\n",
    "        \"ä¸Šæ˜ å¹´ä»½\": year,\n",
    "        \"é›»å½±æè¿°\": description,\n",
    "        \"æµ·å ±åœ–ç‰‡\": poster_url,\n",
    "        \"å¹³å‡è©•åˆ†\": average_score,\n",
    "        \"è©•åˆ†ç¸½æ•¸\": total_ratings,\n",
    "        \"0.5æ˜Ÿ\": star_ratings['0.5'],\n",
    "        \"1æ˜Ÿ\": star_ratings['1'],\n",
    "        \"1.5æ˜Ÿ\": star_ratings['1.5'],\n",
    "        \"2æ˜Ÿ\": star_ratings['2'],\n",
    "        \"2.5æ˜Ÿ\": star_ratings['2.5'],\n",
    "        \"3æ˜Ÿ\": star_ratings['3'],\n",
    "        \"3.5æ˜Ÿ\": star_ratings['3.5'],\n",
    "        \"4æ˜Ÿ\": star_ratings['4'],\n",
    "        \"4.5æ˜Ÿ\": star_ratings['4.5'],\n",
    "        \"5æ˜Ÿ\": star_ratings['5']\n",
    "    }]\n",
    "\n",
    "    df = pd.DataFrame(movie_data)\n",
    "    csv_path = os.path.join(save_path, f\"{safe_query}_movie_info.csv\")\n",
    "    df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"âœ… æˆåŠŸå„²å­˜ï¼š{csv_path}\")\n",
    "\n",
    "    # Step 8ï¼šæ“·å–è©•è«–è³‡æ–™\n",
    "    reviews_url = driver.current_url.rstrip(\"/\") + \"/reviews/by/activity/\"\n",
    "    print(f\"ğŸ“„ å‰å¾€è©•è«–é é¢ï¼š{reviews_url}\")\n",
    "    driver.get(reviews_url)\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "\n",
    "    print(\"âŒ› ç­‰å¾…è©•è«–æ¸…å–®è¼‰å…¥...\")\n",
    "    wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"viewing-list\")))\n",
    "\n",
    "    review_list = driver.find_elements(By.CSS_SELECTOR, \".viewing-list .listitem article\")\n",
    "    print(f\"ğŸ“ æ‰¾åˆ° {len(review_list)} ç­†è©•è«–\")\n",
    "\n",
    "    filename = f\"{safe_query}_reviews.csv\"\n",
    "    output_path = os.path.join(save_path, filename)\n",
    "\n",
    "    def convert_rating_to_number(rating_str):\n",
    "        if not rating_str:\n",
    "            return \"\"\n",
    "        stars = rating_str.count(\"â˜…\")\n",
    "        half = \"Â½\" in rating_str\n",
    "        return stars + 0.5 if half else stars\n",
    "\n",
    "    with open(output_path, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Reviewer\", \"Rating\", \"Date\", \"Content\", \"Likes\"])\n",
    "\n",
    "        for review in review_list:\n",
    "            try:\n",
    "                reviewer = review.find_element(By.CSS_SELECTOR, \".displayname\").text\n",
    "            except:\n",
    "                reviewer = \"ç„¡åç¨±\"\n",
    "\n",
    "            try:\n",
    "                rating_text = review.find_element(By.CSS_SELECTOR, \"span.rating\").text.strip()\n",
    "                rating = convert_rating_to_number(rating_text)\n",
    "            except:\n",
    "                rating = \"\"\n",
    "\n",
    "            try:\n",
    "                date = review.find_element(By.CSS_SELECTOR, \"time.timestamp\").get_attribute(\"datetime\")\n",
    "            except:\n",
    "                date = \"\"\n",
    "\n",
    "            try:\n",
    "                content = review.find_element(By.CSS_SELECTOR, \"div.js-review-body\").text.strip()\n",
    "            except:\n",
    "                content = \"\"\n",
    "\n",
    "            try:\n",
    "                likes_text = review.find_element(By.CSS_SELECTOR, \"span._count_8kxo2_22\").text\n",
    "                likes = int(re.search(r\"\\d+\", likes_text.replace(\",\", \"\")).group())\n",
    "            except:\n",
    "                likes = 0\n",
    "\n",
    "            print(f\"{reviewer} | {rating} | {date} | ğŸ‘ {likes}\")\n",
    "            writer.writerow([reviewer, rating, date, content, likes])\n",
    "\n",
    "    print(f\"âœ… è©•è«–è³‡æ–™å·²å„²å­˜è‡³ï¼š{output_path}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "def convert_csv_to_json(search_query):\n",
    "    safe_query = search_query.strip().replace(\" \", \"_\")\n",
    "    \n",
    "    movie_csv = os.path.join(save_path, f\"{safe_query}_movie_info.csv\")\n",
    "    reviews_csv = os.path.join(save_path, f\"{safe_query}_reviews.csv\")\n",
    "    movie_json = os.path.join(site, f\"{safe_query}_movie_info.json\")\n",
    "    reviews_json = os.path.join(site, f\"{safe_query}_reviews.json\")\n",
    "\n",
    "    os.makedirs(site, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        df_movie = pd.read_csv(movie_csv, encoding='utf-8-sig')\n",
    "        df_reviews = pd.read_csv(reviews_csv, encoding='utf-8-sig')\n",
    "\n",
    "        df_movie.to_json(movie_json, orient='records', force_ascii=False)\n",
    "        df_reviews.to_json(reviews_json, orient='records', force_ascii=False)\n",
    "\n",
    "        print(f\"âœ… å·²è½‰æ› JSON ä¸¦å„²å­˜è‡³ï¼š\\n{movie_json}\\n{reviews_json}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{e.filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f7dfc-955e-4298-846e-997fe0421251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "339ed383-254a-4f8f-8dbb-4b990a726622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd12ed-a5f0-4860-b901-d2cc789f0214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
